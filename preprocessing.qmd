---
title: "preprocessing"
format: html
editor: visual
---



# Install Packages

```{r}

install.packages("pacman")
library("pacman")

p_install("dplyr", force = FALSE)
p_install("ggplot2", force = FALSE)
p_install("readr", force = FALSE)
p_install("tidyr", force = FALSE)
p_install("sf", force = FALSE)
p_install("terra", force = FALSE)
p_install("tmap", force = FALSE)
p_install("zoo", force = FALSE)
p_install("units", force = FALSE)
p_install("plotly", force = FALSE)
p_install("patchwork", force = FALSE)
p_install("tidyverse", force = FALSE)
p_install("rjson", force = FALSE)
p_install("jsonlite", force = FALSE)
p_install("leaflet", force = TRUE)
p_install("XML", force = TRUE)
p_install("lubridate", force = TRUE)

library("dplyr")
library("ggplot2")
library("tidyr")
library("sf")
library("terra")
library("tmap")
library("zoo")
library("zoo")
library("units")
library("plotly")
library("patchwork")
library("tidyverse")
library("rjson")
library("jsonlite")
library("leaflet")
library("XML")
library("lubridate")

```


# Task 1: Import your data

Folgend werden alle .gpx-Files aus dem Ordner *GPS_Daten* eingelesen. Aus den .gpx-Files werden die Koordinaten herausgelesen und jede gefahrene Route / Aktivität in einem neuen Dataframe abgespeichert. Die Dataframes landen alle in einer Liste `single_routes` und können über diese abgerufen und dargestellt werden.In einer weiteren Variate werden alle Daten in einen einzigen Data Frame verpackt `all_routes`.

```{r}


# generate a list of all filenames including the path from the subfolder they are stored in
file_list <- list.files("gps_files_shared", recursive = TRUE, pattern = "\\.gpx$", full.names = TRUE)

# Get Path of the subfolders to extraxt names of subfolders and / or filenames
# Credits go to: https://stackoverflow.com/questions/54082781/extract-portion-of-file-name-using-gsub
file_name <- gsub('.*/(.*).gpx','\\1', file_list)

# creating empty vessels for our soon to be imported data using a for loop
single_routes <- list()
all_routes <- data.frame()

# create a for loop to read in every single gpx file in the subfolder and extraxt the needed values such as coordinates, elevation and timestamps
for (file in file_list) {
  
  # Parse the GPX file using the htmlTreeParse() Function
  # Credits go to: https://www.appsilon.com/post/r-gpx-files
  gpx_parsed <- htmlTreeParse(file = file, useInternalNodes = TRUE)
  
  # Extract data from the parsed GPX file
  coords <- xpathSApply(doc = gpx_parsed, path = "//trkpt", fun = xmlAttrs)
  elevation <- xpathSApply(doc = gpx_parsed, path = "//trkpt/ele", fun = xmlValue)
  time <- xpathSApply(doc = gpx_parsed, path = "//time", fun = xmlValue)
  name <- xpathSApply(doc = gpx_parsed, path = "//name", fun = xmlValue)
  
 
  # Generate new data frame with extracted values
  df <- data.frame(
    name = name,
    time = time[-1],
    lat = as.numeric(coords["lat", ]),
    lon = as.numeric(coords["lon", ]),
    elevation = as.numeric(elevation),
    
    # Extract filenames and subfoldernames using gsub() credits go to: https://stackoverflow.com/questions/54082781/extract-portion-of-file-name-using-gsub
  id = gsub('.*/(.*).gpx','\\1', file),
  curier = as.factor(gsub(".*/([^/]+)/.*", "\\1", file))
  )
  
  # transform into spatial data frame and project to new coordinate system
  df_sf <- st_as_sf(df, coords = c("lon", "lat"), crs = 4326, remove = FALSE)
  df_sf <- st_transform(df_sf, crs = 2056)
  df_sf$x <- st_coordinates(df_sf)[,1]
  df_sf$y <- st_coordinates(df_sf)[,2]
  df_sf <- select(df_sf, id, curier, name, time, x, y, elevation, geometry)
  
 
  # Store every iterration into a singel data frame and send it to the list single_routes()
  single_routes[[file]] <- df_sf
  
  # Store every iterration into new rows of the existing data frame all_routes()
  all_routes <- rbind(all_routes, df_sf)
  
}


```

